import osimport torchdef get_path(train,face_detection):        if face_detection:                images_folder = '/Users/hussamaleem/Face_Detection_Classification/Cropped Face Images'        elif train:                images_folder = os.path.join(os.getcwd(),'archive','simpsons_dataset')    else:                images_folder = '/Users/hussamaleem/Face_Detection_Classification/archive/kaggle_simpson_testset/kaggle_simpson_testset'            return images_folderdef model_saver(epoch,n_trial,time_stamp,start_epoch,model,score_val,score_list,interval):                sav_path = os.path.join(os.getcwd(),'models', time_stamp , 'Num_trial ' + str(n_trial))        if not os.path.exists(sav_path):                    os.makedirs(sav_path)                        if (epoch+1) == (start_epoch+interval):                        torch.save(model.state_dict(), sav_path +  '/Model Parameters')            torch.save(model, sav_path + '/Model.pt')                    elif score_val < min(score_list):                        torch.save(model.state_dict(),sav_path + '/Model Parameters')            torch.save(model, sav_path + '/Model.pt')            class TransformerScheduler:        def __init__(self, optimizer, d_model, warmup_steps):        self.optimizer = optimizer        self.d_model = d_model        self.warmup_steps = warmup_steps        self.step_num = 0    def step(self):        self.step_num += 1        lr = self.get_learning_rate()        for param_group in self.optimizer.param_groups:            param_group['lr'] = lr                def get_last_lr(self):        return [group['lr'] for group in self.optimizer.param_groups]            def get_learning_rate(self):        factor = 0.5 * self.d_model ** (-0.5)                        if self.step_num < self.warmup_steps:            scale = 0.25 * (self.step_num*self.warmup_steps**(-1.5))        else:            scale = 0.25 * (self.warmup_steps*self.warmup_steps**(-1.5))        return factor * scale